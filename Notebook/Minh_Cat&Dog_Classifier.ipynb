{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "tf2-2-2-gpu.2-2.m50",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Minh_Cat&Dog_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmuxJ3DnP39-",
        "colab_type": "code",
        "colab": {},
        "outputId": "3aec9aa8-437b-423c-c914-bd51cdb7582c"
      },
      "source": [
        "# Import Library\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import zipfile\n",
        "import glob\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tgpYce7P3-G",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Helpers Function\n",
        "def gen_label(directory):\n",
        "    label = []\n",
        "    for file in os.listdir(directory):\n",
        "        if (file.split('.')[0] == 'dog'):\n",
        "            label.append(str(1))\n",
        "        elif (file.split('.')[0] == 'cat'):\n",
        "            label.append(str(0))\n",
        "    return label\n",
        "    #print(len(label),\"files in\", directory)\n",
        "    \n",
        "def get_path(directory): #function to generate a list of files' names\n",
        "    path = []\n",
        "    for files in os.listdir(directory):\n",
        "        if '.ipynb_checkpoints' not in files:\n",
        "            path.append(files)\n",
        "        else:\n",
        "            pass\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r4xS790RvRy",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvqXaxv2P3-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = gen_label('/home/jupyter/train/cat')\n",
        "train_y.extend(gen_label('/home/jupyter/train/dog'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_Ov-4JP3-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats = get_path('/home/jupyter/train/cat')\n",
        "train_dogs = get_path('/home/jupyter/train/dog')\n",
        "train_dog = []\n",
        "train_cat = []\n",
        "categories = []\n",
        "for i in train_dogs:\n",
        "    a= './dog/'+i\n",
        "    train_dog.append(a)\n",
        "for i in train_cats:\n",
        "    a= './cat/'+i\n",
        "    train_cat.append(a)\n",
        "train_cat.extend(train_dog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJa4Jzf5P3-Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "30c6c15c-dd46-49ce-ec59-d382208de788"
      },
      "source": [
        "# EDA\n",
        "df = pd.DataFrame({'filename': train_cat,\n",
        "                  'category': train_y})\n",
        "print(df.head())\n",
        "\n",
        "sns.countplot(x='category',data=df).set_title(\"Data Distribution\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             filename category\n",
            "0  ./cat/cat.6259.jpg        0\n",
            "1  ./cat/cat.8290.jpg        0\n",
            "2   ./cat/cat.765.jpg        0\n",
            "3  ./cat/cat.3733.jpg        0\n",
            "4  ./cat/cat.8455.jpg        0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f7Zw83CP3-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#instantiate the constants\n",
        "batch_size = 128\n",
        "img_size = 224\n",
        "epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbniuJEIR50q",
        "colab_type": "text"
      },
      "source": [
        "# Create train and Test set\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiiLBjT1P3-l",
        "colab_type": "code",
        "colab": {},
        "outputId": "529b0fca-4259-49fe-d156-f1cd1619ef90"
      },
      "source": [
        "# Split Train, Test set\n",
        "train_df1, valid_df1 = train_test_split(df, test_size=0.25)\n",
        "print(train_df1.shape)\n",
        "print(valid_df1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18750, 2)\n",
            "(6250, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y665Sn8lP3-p",
        "colab_type": "code",
        "colab": {},
        "outputId": "bc60b178-5cab-46cf-f57e-0f79c52edee9"
      },
      "source": [
        "train_df1['filename'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "./cat/cat.10122.jpg    1\n",
              "./dog/dog.2533.jpg     1\n",
              "./cat/cat.6497.jpg     1\n",
              "./cat/cat.12108.jpg    1\n",
              "./cat/cat.9905.jpg     1\n",
              "                      ..\n",
              "./cat/cat.4186.jpg     1\n",
              "./dog/dog.5252.jpg     1\n",
              "./dog/dog.2789.jpg     1\n",
              "./dog/dog.8472.jpg     1\n",
              "./dog/dog.9658.jpg     1\n",
              "Name: filename, Length: 18750, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "ozKDVE1_P3-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "RFj80-tGP3_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = os.listdir('./cat')\n",
        "dogs = os.listdir('./dog')\n",
        "dog = []\n",
        "cat = []\n",
        "categories = []\n",
        "for i in dogs:\n",
        "    a= './dog/'+i\n",
        "    dog.append(a)\n",
        "for i in points:\n",
        "    a= './cat/'+i\n",
        "    cat.append(a)\n",
        "cat.extend(dog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "lYOeoBAVP3_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for point in cat:\n",
        "    category = point.split('/')[1]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "    \n",
        "df = pd.DataFrame({'point': cat,\n",
        "                   'category': categories})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "wz5KhtvnP3_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Constant\n",
        "FAST_RUN = False\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "kTBrEodDP3_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preprocess\n",
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur9mLB8bP3_g",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d103215-3f21-4005-d67e-e49792fcc38e"
      },
      "source": [
        "# EDA\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "okOgAePBP3_j",
        "colab_type": "code",
        "colab": {},
        "outputId": "632da308-87d3-4825-ec1b-8f6e31d16ff1"
      },
      "source": [
        "# Create Generator\n",
        "train_df[\"category\"] = train_df[\"category\"].replace({0: '0', 1: '1'}) \n",
        "validate_df[\"category\"] = validate_df[\"category\"].replace({0: '0', 1: '1'}) \n",
        "batch_size=32\n",
        "\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range= 30,\n",
        "    rescale= 1./255,\n",
        "    shear_range= 0.1,\n",
        "    zoom_range= 0.2,\n",
        "    horizontal_flip= True, \n",
        "    width_shift_range= 0.2,\n",
        "    height_shift_range= 0.2\n",
        "    # preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    directory=None, \n",
        "    x_col='point',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "riCQ3BOJP3_o",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2a448ae-2729-4a91-a156-0a94a309402f"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        "    )\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    directory=None, \n",
        "    x_col='point',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2ffg1QQRPZS",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "ETHWZeOyP3_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "2YpaCXPSP3_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def define_model():\n",
        "    # load model\n",
        "    model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(50, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = tf.keras.Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    opt = tf.keras.optimizers.RMSprop(lr=0.001, momentum=0.9)\n",
        "    sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9) # Increase momentum to 0.9\n",
        "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = define_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "fUdgvX3SP3_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdTqIbxrP3_6",
        "colab_type": "code",
        "colab": {},
        "outputId": "45bd5cb4-4eea-4bf2-b5b1-663d998aa569"
      },
      "source": [
        "epochs=20\n",
        "history = model.fit(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples//batch_size,\n",
        "    steps_per_epoch=train_generator.samples//batch_size,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 270s 432ms/step - loss: 0.1315 - accuracy: 0.9456 - val_loss: 0.0699 - val_accuracy: 0.9780 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 268s 430ms/step - loss: 0.1132 - accuracy: 0.9563 - val_loss: 0.0596 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0964 - accuracy: 0.9617 - val_loss: 0.0625 - val_accuracy: 0.9782 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9635\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0967 - accuracy: 0.9635 - val_loss: 0.0552 - val_accuracy: 0.9788 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0809 - accuracy: 0.9672 - val_loss: 0.0467 - val_accuracy: 0.9820 - lr: 0.0050\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0736 - accuracy: 0.9697 - val_loss: 0.0427 - val_accuracy: 0.9816 - lr: 0.0050\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0768 - accuracy: 0.9689 - val_loss: 0.0433 - val_accuracy: 0.9824 - lr: 0.0050\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0716 - accuracy: 0.9712 - val_loss: 0.0446 - val_accuracy: 0.9814 - lr: 0.0050\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9727\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0699 - accuracy: 0.9727 - val_loss: 0.0496 - val_accuracy: 0.9802 - lr: 0.0050\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 269s 430ms/step - loss: 0.0621 - accuracy: 0.9755 - val_loss: 0.0420 - val_accuracy: 0.9812 - lr: 0.0025\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 268s 430ms/step - loss: 0.0666 - accuracy: 0.9730 - val_loss: 0.0421 - val_accuracy: 0.9826 - lr: 0.0025\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 268s 429ms/step - loss: 0.0639 - accuracy: 0.9747 - val_loss: 0.0461 - val_accuracy: 0.9814 - lr: 0.0025\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9737\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "625/625 [==============================] - 269s 431ms/step - loss: 0.0643 - accuracy: 0.9737 - val_loss: 0.0456 - val_accuracy: 0.9820 - lr: 0.0025\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 269s 430ms/step - loss: 0.0580 - accuracy: 0.9750 - val_loss: 0.0454 - val_accuracy: 0.9804 - lr: 0.0012\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9777\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "625/625 [==============================] - 269s 431ms/step - loss: 0.0574 - accuracy: 0.9777 - val_loss: 0.0441 - val_accuracy: 0.9810 - lr: 0.0012\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 270s 431ms/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.0423 - val_accuracy: 0.9814 - lr: 6.2500e-04\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9785\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "625/625 [==============================] - 271s 433ms/step - loss: 0.0549 - accuracy: 0.9785 - val_loss: 0.0413 - val_accuracy: 0.9826 - lr: 6.2500e-04\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 272s 435ms/step - loss: 0.0558 - accuracy: 0.9778 - val_loss: 0.0410 - val_accuracy: 0.9826 - lr: 3.1250e-04\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9786\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "625/625 [==============================] - 272s 435ms/step - loss: 0.0530 - accuracy: 0.9786 - val_loss: 0.0412 - val_accuracy: 0.9820 - lr: 3.1250e-04\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 273s 436ms/step - loss: 0.0564 - accuracy: 0.9760 - val_loss: 0.0401 - val_accuracy: 0.9818 - lr: 1.5625e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBaA4g9sRTWx",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LYNw5J0P3_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('catdog_mobilenetv2_minh2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}